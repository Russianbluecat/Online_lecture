{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "장윤정 부부 '현금 120억' 주고 산 빌라…제이홉·공유·김고은도 샀다\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests # 라이브러리 임포트 \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://n.news.naver.com/article/277/0005445416') #웹페이지 갖고 오기 \n",
    " \n",
    "soup = BeautifulSoup(res.content,'html.parser') #웹페이지 파싱하기\n",
    "\n",
    "mydata = soup.find('h2','media_end_head_headline') #필요한 데이터 추출하기/ class_ 이거 굳이 안써도 돼 \n",
    "\n",
    "print(mydata.get_text()) #추출한 데이터 활용하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타이틀 말고 밑에 기사 입력 시간 추출해보기 \n",
    "\t<em class=\"media_end_head_info_datestamp_term\">입력</em><span class=\"media_end_head_info_datestamp_time _ARTICLE_DATE_TIME\" data-date-time=\"2024-07-14 20:45:26\" data-date-time-age-in-minutes=\"918\">2024.07.14. 오후 8:45</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024.07.14. 오후 8:45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests # 라이브러리 임포트 \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://n.news.naver.com/article/277/0005445416') #웹페이지 갖고 오기 \n",
    " \n",
    "soup = BeautifulSoup(res.content,'html.parser') #웹페이지 파싱하기\n",
    "\n",
    "mydata = soup.find('span','media_end_head_info_datestamp_time _ARTICLE_DATE_TIME') #필요한 데이터 추출하기/ class_ 이거 굳이 안써도 돼 \n",
    "\n",
    "print(mydata.get_text()) #추출한 데이터 활용하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 시간: 2024.07.14. 오후 8:45\n",
      "수정 시간: 2024.07.14. 오후 8:49\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"https://n.news.naver.com/article/277/0005445416\")\n",
    "\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "\n",
    "date_info = soup.find_all('div',class_='media_end_head_info_datestamp_bunch')\n",
    "\n",
    "if date_info:\n",
    "    input_time = date_info[0].find('span', class_='media_end_head_info_datestamp_time _ARTICLE_DATE_TIME').get_text()\n",
    "    modify_time = date_info[1].find('span', class_='media_end_head_info_datestamp_time _ARTICLE_MODIFY_DATE_TIME').get_text()\n",
    "else:\n",
    "    input_time = \"입력 시간을 찾을 수 없습니다.\"\n",
    "    modify_time = \"수정 시간을 찾을 수 없습니다.\"\n",
    "    \n",
    "# 추출한 데이터 활용하기\n",
    "print(f\"입력 시간: {input_time}\")\n",
    "print(f\"수정 시간: {modify_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기사가 여러개라면... (GPT 문의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# 기사 URL 리스트\n",
    "urls = [\n",
    "    'https://n.news.naver.com/article/277/0005445416',\n",
    "    # 여기에 나머지 9개의 URL을 추가하세요.\n",
    "]\n",
    "\n",
    "# 각 기사에서 입력 시간과 수정 시간을 추출하는 함수\n",
    "def get_article_times(url):\n",
    "    try:\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()  # HTTP 에러가 발생하면 예외를 발생시킴\n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "        # 날짜 정보가 들어있는 div 태그를 찾기\n",
    "        date_info = soup.find_all('div', class_='media_end_head_info_datestamp_bunch')\n",
    "\n",
    "        # 입력 및 수정 시간을 추출하기\n",
    "        if date_info:\n",
    "            input_time = date_info[0].find('span', class_='media_end_head_info_datestamp_time _ARTICLE_DATE_TIME').get_text()\n",
    "            modify_time = date_info[1].find('span', class_='media_end_head_info_datestamp_time _ARTICLE_MODIFY_DATE_TIME').get_text()\n",
    "        else:\n",
    "            input_time = \"입력 시간을 찾을 수 없습니다.\"\n",
    "            modify_time = \"수정 시간을 찾을 수 없습니다.\"\n",
    "\n",
    "        return input_time, modify_time\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: {e}\", f\"Error: {e}\"\n",
    "\n",
    "# 모든 기사에서 입력 시간과 수정 시간을 추출하여 출력\n",
    "for url in urls:\n",
    "    input_time, modify_time = get_article_times(url)\n",
    "    print(f\"URL: {url}\")\n",
    "    print(f\"입력 시간: {input_time}\")\n",
    "    print(f\"수정 시간: {modify_time}\")\n",
    "    print('-' * 40)\n",
    "    time.sleep(1)  # 1초 대기\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
